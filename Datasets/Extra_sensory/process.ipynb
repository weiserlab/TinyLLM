{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sensor_data_with_nan(X):\n",
    "    # Initialize an array to hold normalized data\n",
    "    X_norm = np.empty_like(X)\n",
    "    \n",
    "    for i in range(X.shape[1]):\n",
    "        # Extract the column, handling NaNs\n",
    "        column = X[:, i]\n",
    "        valid_values = column[~np.isnan(column)]\n",
    "        \n",
    "        if valid_values.size > 0:\n",
    "            col_min = valid_values.min()\n",
    "            col_max = valid_values.max()\n",
    "            \n",
    "            if col_max > col_min:  # Avoid division by zero\n",
    "                X_norm[:, i] = (column - col_min) / (col_max - col_min)\n",
    "            else:\n",
    "                X_norm[:, i] = 0.5  # If all valid values are the same, normalize to 0.5\n",
    "        else:\n",
    "            X_norm[:, i] = np.nan  # If all values are NaN, keep the column as NaN\n",
    "    \n",
    "    return np.round(X_norm, 3)\n",
    "\n",
    "def format_input_data(X_norm):\n",
    "    # Format the normalized sensor data with all entries in a single set of brackets and separated by spaces\n",
    "    formatted_data = []\n",
    "    for row in X_norm:\n",
    "        formatted_row = \"[\" + \" \".join([f\"{value if not np.isnan(value) else 'nan'}\" for value in row]) + \"]\"\n",
    "        formatted_data.append(formatted_row)\n",
    "    return formatted_data\n",
    "\n",
    "def parse_header_of_csv(csv_str):\n",
    "    # Isolate the headline columns:\n",
    "    headline = csv_str[:csv_str.index(b'\\n')]\n",
    "    columns = headline.split(b',')\n",
    "\n",
    "    # The first column should be timestamp:\n",
    "    assert columns[0] == b'timestamp'\n",
    "    # The last column should be label_source:\n",
    "    assert columns[-1] == b'label_source'\n",
    "    \n",
    "    # Search for the column of the first label:\n",
    "    for (ci, col) in enumerate(columns):\n",
    "        if col.startswith(b'label:'):\n",
    "            first_label_ind = ci\n",
    "            break\n",
    "\n",
    "    # Feature columns come after timestamp and before the labels:\n",
    "    feature_names = columns[1:first_label_ind]\n",
    "    # Then come the labels, till the one-before-last column:\n",
    "    label_names = columns[first_label_ind:-1]\n",
    "    for (li, label) in enumerate(label_names):\n",
    "        # In the CSV the label names appear with prefix 'label:', but we don't need it after reading the data:\n",
    "        assert label.startswith(b'label:')\n",
    "        label_names[li] = label.replace(b'label:', b'')\n",
    "    \n",
    "    return (feature_names, label_names)\n",
    "\n",
    "def parse_body_of_csv(csv_str, n_features):\n",
    "    # Read the entire CSV body into a single numeric matrix:\n",
    "    full_table = np.loadtxt(StringIO(csv_str.decode('utf-8')), delimiter=',', skiprows=1)\n",
    "    \n",
    "    # Timestamp is the primary key for the records (examples):\n",
    "    timestamps = full_table[:, 0].astype(int)\n",
    "    \n",
    "    # Read the sensor features:\n",
    "    X = full_table[:, 1:(n_features+1)]\n",
    "    \n",
    "    # Read the binary label values, and the 'missing label' indicators:\n",
    "    trinary_labels_mat = full_table[:, (n_features+1):-1]  # This should have values of either 0., 1. or NaN\n",
    "    M = np.isnan(trinary_labels_mat)  # M is the missing label matrix\n",
    "    Y = np.where(M, 0, trinary_labels_mat) > 0.  # Y is the label matrix\n",
    "    \n",
    "    return timestamps, X, Y\n",
    "\n",
    "def normalize_sensor_data(X):\n",
    "    # Normalize sensor data between 0 and 1 with 3 decimals precision\n",
    "    X_min = X.min(axis=0)\n",
    "    X_max = X.max(axis=0)\n",
    "    X_norm = (X - X_min) / (X_max - X_min)\n",
    "    return np.round(X_norm, 3)\n",
    "\n",
    "def prettify_label_name(label):\n",
    "    label_mapping = {\n",
    "        'FIX_walking': 'Walking',\n",
    "        'FIX_running': 'Running',\n",
    "        'LOC_main_workplace': 'At main workplace',\n",
    "        'OR_indoors': 'Indoors',\n",
    "        'OR_outside': 'Outside',\n",
    "        'LOC_home': 'At home',\n",
    "        'FIX_restaurant': 'At a restaurant',\n",
    "        'OR_exercise': 'Exercise',\n",
    "        'LOC_beach': 'At the beach',\n",
    "        'OR_standing': 'Standing',\n",
    "        'WATCHING_TV': 'Watching TV'\n",
    "    }\n",
    "    return label_mapping.get(label, label)\n",
    "\n",
    "def prettify_labels(label_names, Y):\n",
    "    # Create a space-separated string of active labels for each timestamp using the prettified label names\n",
    "    pretty_labels = []\n",
    "    for y in Y:\n",
    "        active_labels = [\n",
    "            prettify_label_name(label.decode('utf-8')) \n",
    "            for label, active in zip(label_names, y) if active\n",
    "        ]\n",
    "        pretty_labels.append(\" \".join(active_labels))\n",
    "    return pretty_labels\n",
    "\n",
    "\n",
    "prompt = 'You are provided with sensor readings that include high-frequency motion-reactive sensors (accelerometer, gyroscope, magnetometer, watch accelerometer), location services, audio, watch compass, phone state indicators, and additional low-frequency sensors sampled once per minute. The data may contain NaN values and each sensor value is normalized between 0 and 1. Based on these sensor readings, identify the users activity, which may include one or more of the following:\\n\"Phone on table\", \"Sitting\", \"Indoors\", \"At home\", \"Lying down\", \"Talking\", \"Sleeping\", \"At main workplace\", \"Phone in pocket\", \"Eating\", \"Watching TV\", \"Surfing the internet\", \"Standing\", \"Walking\", \"Outside\", \"With friends\", \"Phone in hand\", \"Computer work\", \"With co-workers\", \"Dressing\", \"Cooking\", \"Washing dishes\", \"On a bus\", \"Grooming\", \"Drive - Im the driver\", \"Toilet\", \"At school\", \"In a car\", \"Drinking (alcohol)\", \"In a meeting\", \"Drive - Im a passenger\", \"Bathing - shower\", \"Strolling\", \"Singing\", \"Shopping\", \"At a restaurant\", \"Doing laundry\", \"Running\", \"Exercise\", \"Stairs - going up\", \"Stairs - going down\", \"Bicycling\", \"Lab work\", \"In class\", \"Cleaning\", \"At a party\", \"At a bar\", \"At the beach\", \"At the gym\", \"Elevator\", \"Phone in bag\".'\n",
    "\n",
    "def create_csv_per_user(user_data_dir, output_dir):\n",
    "    # Iterate over each user file in the provided directory\n",
    "    for user_file in os.listdir(user_data_dir):\n",
    "        if user_file.endswith('.csv.gz'):\n",
    "            print(user_file)\n",
    "            # Read the compressed CSV file\n",
    "            with gzip.open(os.path.join(user_data_dir, user_file), 'rb') as f:\n",
    "                csv_str = f.read()\n",
    "            \n",
    "            # Parse the header and body of the CSV\n",
    "            feature_names, label_names = parse_header_of_csv(csv_str)\n",
    "            timestamps, X, Y = parse_body_of_csv(csv_str, len(feature_names))\n",
    "            \n",
    "            # Normalize sensor data, handling NaNs\n",
    "            X_norm = normalize_sensor_data_with_nan(X)\n",
    "            \n",
    "            # Format the normalized data\n",
    "            input_data = format_input_data(X_norm)\n",
    "            \n",
    "            # Prettify labels\n",
    "            pretty_labels = prettify_labels(label_names, Y)\n",
    "            \n",
    "            # Combine input (formatted normalized sensor data) and response (pretty labels)\n",
    "            data = {'Instruction': prompt , 'Input': input_data, 'Response': pretty_labels}\n",
    "            df = pd.DataFrame(data)\n",
    "            \n",
    "            # Write to CSV\n",
    "            output_file = os.path.join(output_dir, f\"{user_file[:-7]}.csv\")\n",
    "            df.to_csv(output_file, index=False)\n",
    "\n",
    "# Example usage:\n",
    "# create_csv_per_user_updated('/path/to/user_data', '/path/to/output_csvs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83CF687B-7CEC-434B-9FE8-00C3D5799BE6.features_labels.csv.gz\n",
      "481F4DD2-7689-43B9-A2AA-C8772227162B.features_labels.csv.gz\n",
      "7CE37510-56D0-4120-A1CF-0E23351428D2.features_labels.csv.gz\n",
      "1DBB0F6F-1F81-4A50-9DF4-CD62ACFA4842.features_labels.csv.gz\n",
      "E65577C1-8D5D-4F70-AF23-B3ADB9D3DBA3.features_labels.csv.gz\n",
      "2C32C23E-E30C-498A-8DD2-0EFB9150A02E.features_labels.csv.gz\n",
      "A7599A50-24AE-46A6-8EA6-2576F1011D81.features_labels.csv.gz\n",
      "7D9BB102-A612-4E2A-8E22-3159752F55D8.features_labels.csv.gz\n",
      "B09E373F-8A54-44C8-895B-0039390B859F.features_labels.csv.gz\n",
      "27E04243-B138-4F40-A164-F40B60165CF3.features_labels.csv.gz\n",
      "78A91A4E-4A51-4065-BDA7-94755F0BB3BB.features_labels.csv.gz\n",
      "40E170A7-607B-4578-AF04-F021C3B0384A.features_labels.csv.gz\n",
      "BE3CA5A6-A561-4BBD-B7C9-5DF6805400FC.features_labels.csv.gz\n",
      "CDA3BBF7-6631-45E8-85BA-EEB416B32A3C.features_labels.csv.gz\n",
      "B7F9D634-263E-4A97-87F9-6FFB4DDCB36C.features_labels.csv.gz\n",
      "B9724848-C7E2-45F4-9B3F-A1F38D864495.features_labels.csv.gz\n",
      "33A85C34-CFE4-4732-9E73-0A7AC861B27A.features_labels.csv.gz\n",
      "9759096F-1119-4E19-A0AD-6F16989C7E1C.features_labels.csv.gz\n",
      "FDAA70A1-42A3-4E3F-9AE3-3FDA412E03BF.features_labels.csv.gz\n",
      "F50235E0-DD67-4F2A-B00B-1F31ADA998B9.features_labels.csv.gz\n",
      "4E98F91F-4654-42EF-B908-A3389443F2E7.features_labels.csv.gz\n",
      "61359772-D8D8-480D-B623-7C636EAD0C81.features_labels.csv.gz\n",
      "8023FE1A-D3B0-4E2C-A57A-9321B7FC755F.features_labels.csv.gz\n",
      "96A358A0-FFF2-4239-B93E-C7425B901B47.features_labels.csv.gz\n",
      "A5A30F76-581E-4757-97A2-957553A2C6AA.features_labels.csv.gz\n",
      "797D145F-3858-4A7F-A7C2-A4EB721E133C.features_labels.csv.gz\n",
      "C48CE857-A0DD-4DDB-BEA5-3A25449B2153.features_labels.csv.gz\n",
      "D7D20E2E-FC78-405D-B346-DBD3FD8FC92B.features_labels.csv.gz\n",
      "0BFC35E2-4817-4865-BFA7-764742302A2D.features_labels.csv.gz\n",
      "0A986513-7828-4D53-AA1F-E02D6DF9561B.features_labels.csv.gz\n",
      "86A4F379-B305-473D-9D83-FC7D800180EF.features_labels.csv.gz\n",
      "098A72A5-E3E5-4F54-A152-BBDA0DF7B694.features_labels.csv.gz\n",
      "24E40C4C-A349-4F9F-93AB-01D00FB994AF.features_labels.csv.gz\n",
      "ECECC2AB-D32F-4F90-B74C-E12A1C69BBE2.features_labels.csv.gz\n",
      "11B5EC4D-4133-4289-B475-4E737182A406.features_labels.csv.gz\n",
      "5119D0F8-FCA8-4184-A4EB-19421A40DE0D.features_labels.csv.gz\n",
      "74B86067-5D4B-43CF-82CF-341B76BEA0F4.features_labels.csv.gz\n",
      "9DC38D04-E82E-4F29-AB52-B476535226F2.features_labels.csv.gz\n",
      "CCAF77F0-FABB-4F2F-9E24-D56AD0C5A82F.features_labels.csv.gz\n",
      "136562B6-95B2-483D-88DC-065F28409FD2.features_labels.csv.gz\n",
      "BEF6C611-50DA-4971-A040-87FB979F3FC1.features_labels.csv.gz\n",
      "59EEFAE0-DEB0-4FFF-9250-54D2A03D0CF2.features_labels.csv.gz\n",
      "5EF64122-B513-46AE-BCF1-E62AAC285D2C.features_labels.csv.gz\n",
      "61976C24-1C50-4355-9C49-AAE44A7D09F6.features_labels.csv.gz\n",
      "59818CD2-24D7-4D32-B133-24C2FE3801E5.features_labels.csv.gz\n",
      "1155FF54-63D3-4AB2-9863-8385D0BD0A13.features_labels.csv.gz\n",
      "CF722AA9-2533-4E51-9FEB-9EAC84EE9AAC.features_labels.csv.gz\n",
      "0E6184E1-90C0-48EE-B25A-F1ECB7B9714E.features_labels.csv.gz\n",
      "A5CDF89D-02A2-4EC1-89F8-F534FDABDD96.features_labels.csv.gz\n",
      "5152A2DF-FAF3-4BA8-9CA9-E66B32671A53.features_labels.csv.gz\n",
      "81536B0A-8DBF-4D8A-AC24-9543E2E4C8E0.features_labels.csv.gz\n",
      "1538C99F-BA1E-4EFB-A949-6C7C47701B20.features_labels.csv.gz\n",
      "3600D531-0C55-44A7-AE95-A7A38519464E.features_labels.csv.gz\n",
      "CA820D43-E5E2-42EF-9798-BE56F776370B.features_labels.csv.gz\n",
      "806289BC-AD52-4CC1-806C-0CDB14D65EB6.features_labels.csv.gz\n",
      "A76A5AF5-5A93-4CF2-A16E-62353BB70E8A.features_labels.csv.gz\n",
      "665514DE-49DC-421F-8DCB-145D0B2609AD.features_labels.csv.gz\n",
      "00EABED2-271D-49D8-B599-1D4A09240601.features_labels.csv.gz\n",
      "99B204C0-DD5C-4BB7-83E8-A37281B8D769.features_labels.csv.gz\n",
      "4FC32141-E888-4BFF-8804-12559A491D8C.features_labels.csv.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create_csv_per_user('/path/to/user_data', '/path/to/output_csvs')\n",
    "create_csv_per_user('./', '../processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/labiour/Documents/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 60/60 [00:00<00:00, 511500.49files/s]\n",
      "Generating train split: 377346 examples [00:03, 96589.20 examples/s]\n"
     ]
    }
   ],
   "source": [
    "fw = load_dataset(\"../processed/\", split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Instruction', 'Input', 'Response'],\n",
       "    num_rows: 377346\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fw"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
